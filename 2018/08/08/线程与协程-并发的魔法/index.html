<!DOCTYPE html>
<html>
  <!-- Html Head Tag-->
  <head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="">
  <meta name="author" content="">
  <!-- Open Graph Data -->
  <meta property="og:title" content="线程与协程-并发的魔法"/>
  <meta property="og:description" content="" />
  <meta property="og:site_name" content="hanayuki"/>
  <meta property="og:type" content="article" />
  <meta property="og:image" content="https://kafuuchino.github.io/blog"/>
  
    <link rel="alternate" href="/atom.xml" title="hanayuki" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  

  <!-- Site Title -->
  <title>hanayuki</title>

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="/blog/css/bootstrap.min.css">
  <!-- Custom CSS -->
  
  <link rel="stylesheet" href="/blog/css/style.light.css">
  <link rel="stylesheet" href="/blog/css/github.css">

  <!-- Google Analytics -->
  

</head>

  <body>
    <!-- Page Header -->


<header class="site-header header-background" style="background-image: url(/blog/img/mv_img.jpg)">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <div class="page-title with-background-image">
          <p class="title">线程与协程-并发的魔法</p>
          <p class="subtitle"></p>
        </div>
        <div class="site-menu with-background-image">
          <ul>
            
              <li>
                <a href="/blog/">
                  
                  Home
                  
                </a>
              </li>
            
              <li>
                <a href="/blog/archives">
                  
                  Archives
                  
                </a>
              </li>
            
              <li>
                <a href="https://github.com/bbrabbitt/blog/issues/new">
                  
                  Github
                  
                </a>
              </li>
            
              <li>
                <a href="mailto:soranomethods@yahoo.co.jp">
                  
                  Email
                  
                </a>
              </li>
            
          </ul>
        </div>
      </div>
    </div>
  </div>
</header>

<article>
  <div class="container typo">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <div class="post-info text-muted">
          
          <!-- Date -->
          <span class="date-time info">On
            <span class="date">2018-08-08</span>
            <span class="time">21:44:34</span>
          </span>
          
          <!--  Categories  -->
            <span class="categories info">Under 

<a href="/blog/categories/备忘录/">备忘录</a>
</span>
          
        </div>
        <!-- Tags -->
        
          <div class="post-tags text-muted">
            Tags: 

<a class="tag" href="/blog/tags/并发/">#并发</a>


          </div>
        
        <!-- Post Main Content -->
        <div class="post-content">
          <p>该文章仅记录作者本人对并发的一点理解，代码只在Mac OS X 10.11上进行测试且不保证正确，如因本备忘录导致任何生产环境的问题本人概不负责。</p>
<p>在信息行业高速增长的21世纪，人们对互联网越发依赖，而对获取信息的速度也越来越严格。因此程序员一直在想办法优化代码以提高服务器的性能。在对代码优化时我们可以简化一些耗时的操作（比如，显而易见的，向标准输出打印数据），<a id="more"></a>但随着代码库发展越来越成熟，很多耗时的操作都已经被工程师大佬们调到几乎最优速度，而stackoverflow等程序员社区也都有着关于如何优化代码的大量回答（这并不是说优化这些耗时操作不重要，事实上很多代码还是会因为程序员的错误习惯如滥用反射机制而十分缓慢，但这不是这篇文章的重点）。因此我们应把目光放在另一面：在执行一些IO密集的代码时我们在让CPU干什么。在我们执行一个耗时的IO操作时（比如从网络上下载一张图片），我们的程序仍然在CPU上运行，等待系统通知IO操作完成或者被操作系统调度。在这个期间CPU可能会浪费数十万CPU时间在等待IO返回结果。在单核系统上这会降低整个系统的执行性能，而在多核系统上操作系统也不能及时将耗时操作调度到别的核心上提高性能。因此，学会如何运用等待IO时浪费的时间是很有必要的。</p>
<p>这篇文章大致分成两个部分，第一个部分讲了多线程带来的问题以及操作系统提供的解决方案，第二部分讲了不同的线程和协程机制是如何让我们方便地提升程序性能。</p>
<p>本文假设读者有基本的编程技能并能根据所学内容能够举一反三。</p>
<h2 id="0x01-操作系统的线程调度"><a class="header-anchor" href="#0x01-操作系统的线程调度">¶</a>0x01 操作系统的线程调度</h2>
<p><em>本章所有代码都使用C编写，Clang编译，仅在Mac OS X 10.11上测试通过</em></p>
<p>不论是Unix还是Windows亦或是其他的一些操作系统，在底层它们都实现了自己的线程调度算法，并提供了一些库函数和系统调用供程序员进行最基本的线程控制。下面我们就从Unix系统提供的一些线程机制来探究如何提高程序的性能，不过相同的机制在Windows上也有类似实现。</p>
<h3 id="01-最简单的线程控制"><a class="header-anchor" href="#01-最简单的线程控制">¶</a>01 最简单的线程控制</h3>
<h4 id="一段简单的代码"><a class="header-anchor" href="#一段简单的代码">¶</a>一段简单的代码</h4>
<p>Unix是一个分时操作系统，也就是说操作系统会保证每个线程都能有一定运行时间而不是保证在一定时间内能完成任务（后者为实时系统的特征）。因此Unix自然也提供了一个线程库让程序员能够自由地创建线程并执行。这个库的头文件为pthread.h。下面我们用一段代码简单的介绍如何使用这个库。</p>
<p>一个打印两个数字的程序</p>
<pre><code>#include &lt;stdio.h&gt;
#include &lt;unistd.h&gt;
#include &lt;pthread.h&gt;
 
void* print_int(void* i);
 
int main() {
    pthread_t t1,t2;
    int k=1, j=2;
    pthread_create(&amp;t1, NULL, print_int, (void*)&amp;k);
    pthread_create(&amp;t2, NULL, print_int, (void*)&amp;j);
    pthread_join(t1, NULL);
    pthread_join(t2, NULL);
    printf(&quot;program exit\n&quot;);
    return 0;
}
 
void* print_int(void* i) {
    sleep(1) //假设在工作...
    printf(&quot;the thread id is %d\n&quot;, *(int*)i);
    return NULL;
}
</code></pre>
<p>当我们编译运行这段代码时，程序应当输出</p>
<blockquote>
<p>the thread id is 1<br>
the thread id is 2<br>
program exit</p>
</blockquote>
<p>或者</p>
<blockquote>
<p>the thread id is 2<br>
the thread id is 1<br>
program exit</p>
</blockquote>
<h4 id="这段代码到底做了什么"><a class="header-anchor" href="#这段代码到底做了什么">¶</a>这段代码到底做了什么</h4>
<p>那么，上面这段代码到底干了什么呢？这里我们用到了两个库函数：<em>pthread_create</em>和<em>pthread_join</em>。pthread_create创建一个线程并将线程存入第一个参数提供的线程变量，pthread_join同步多个线程，让接下来的代码在所有被join的线程结束后才能执行。这个过程被称为阻塞。而启动后的线程则是由操作系统调度，操作系统能够在任何位置切换上下文，也就是切换线程。因此我们可能会看到线程输出顺序不同。</p>
<h4 id="这会带来什么问题？"><a class="header-anchor" href="#这会带来什么问题？">¶</a>这会带来什么问题？</h4>
<p>这段代码仅仅是打印了两个互不相干的变量，看起来并没有什么问题。但是真正的系统中很少有这样简单的代码。下面我们来看一个稍微复杂一点的程序，并思考这段程序是否有出错的可能。</p>
<p>一个计算数组所有数总和的程序</p>
<pre><code>#include &lt;stdio.h&gt;
#include &lt;pthread.h&gt;
 
void* array_sum(void* array);
 
int main() {
    pthread_t t1,t2;
    int somearray[10] = {1,2,3,4,5,6,7,8,9,0};
    pthread_create(&amp;t1, NULL, array_sum, (void*)&amp;somearray);
    pthread_create(&amp;t2, NULL, array_sum, (void*)&amp;somearray);
    pthread_join(t1, NULL);
    pthread_join(t2, NULL);
    printf(&quot;the sum of array is %d&quot;,somearray[9]);
}
 
void* array_sum(void* array) {
    int i;
    int* parray = (int*)array;
    for(i=0;i&lt;9;i++) {
        if( parray[i] != 0) {
            parray[9] += parray[i];
            parray[i] = 0;
            continue;
        }
    }
    return NULL;
}
</code></pre>
<p>由于给新线程传多个参数需要传结构体，这里我们在数组的最后一个元素中存放总和，并将每个计算过的数值置为0以判断这个数是否被累加过。</p>
<p>这段代码乍看上去没有任何问题，但如果将它编译执行，我们偶尔会得到一个错误的答案（在我的电脑上1000次执行大概会出错6到8次，答案从6到51不等）。这里的问题就出在多线程程序最常见的问题之一：共享变量。</p>
<h4 id="共享变量带来的错误"><a class="header-anchor" href="#共享变量带来的错误">¶</a>共享变量带来的错误</h4>
<p>在上面这段程序中我们给两个线程传了同一个变量的地址，因此这两个线程修改了同一个变量。我们在这里要时刻记住操作系统能够在任何位置挂起一个线程并执行另一个，甚至能在允许的情况下同时执行两个线程。因此操作系统可能会在t1执行判断时挂起线程，让t2累加值后再将t2挂起，然后再让t1累加值。此时t2还没来得及将数组的元素置为0，而t1又认为这个元素还没被累加过而又累加一次，因此我们会得到一个错误的结果。如果我们将数组的元素增多或者在累加和元素置0两条指令间插入一些其他的逻辑代码，带来的误差可能会更大。</p>
<p>下面这张图简单表明系统内部到底发生了什么。</p>
<img src="/blog/2018/08/08/线程与协程-并发的魔法/threaddemo.png" title="出现问题的系统上下文切换的简化版">
<p>可能有些人会认为这种刚好在中间切换的几率太小了，如果差一步那么t1就只会将0加上去或者直接开始加下一个元素。但永远要记住，在多线程编程中最坏的情况永远都会发生。而两个线程同时修改同一个变量有一个专门的术语——<strong>竞态条件(racing condition)</strong>。要而接下来我们讨论的一系列线程和协程机制都是用来保护我们远离竞态条件的同时能让我们提高程序的性能。幸运的是，系统本身就给我们提供了一些保护机制。下面我们来看一看系统提供的保护机制。</p>
<h3 id="02-互斥锁和自旋锁"><a class="header-anchor" href="#02-互斥锁和自旋锁">¶</a>02 互斥锁和自旋锁</h3>
<p>在所有操作系统的保护机制中，最简单的一种便是互斥锁。顾名思义，它就像一把锁锁在共享变量上，阻止其他线程对这个变量进行修改。在每次线程需要访问一个可变变量时都需要进行上锁(lock)，然后在操作结束后进行解锁(unlock)。我们来改进一下上面的代码来让它输出正确的结果。</p>
<p>一个加锁后的计算数组所有数总和的程序</p>
<pre><code>#include &lt;stdio.h&gt;
#include &lt;pthread.h&gt;
 
void* array_sum(void* array);
static pthread_mutex_t testlock;
 
int main() {
    pthread_mutex_init(&amp;testlock, NULL);
    pthread_t t1,t2;
    int somearray[10] {1,2,3,4,5,6,7,8,9,0}
    pthread_create(&amp;t1, NULL, array_sum, (void*)&amp;somearray);
    pthread_create(&amp;t2, NULL, array_sum, (void*)&amp;somearray);
    pthread_join(t1, NULL);
    pthread_join(t2, NULL);
    printf(&quot;the sum of array is %d&quot;,somearray[9]);
    pthread_mutex_destroy(&amp;testlock);
    free(&amp;testlock);
    return 0;
}
 
void* array_sum(void* array) {
    int i;
    pthread_mutex_lock(&amp;testlock);
    int* parray = (int*)array;
    for(i=0;i&lt;9;i++) {
        if( parray[i] != 0) {
            parray[9] += parray[i];
            parray[i] = 0;
            break;
        }
    }
    pthread_mutex_unlock(&amp;testlock);
    return NULL;
}
</code></pre>
<p>我们在这段代码里初始化了一个<em>pthread_mutex_t</em>类型的变量作为我们使用的互斥锁，然后在主函数中使用<em>pthread_mutex_init</em>初始化了这个互斥锁，然后在需要操作共享变量的地方使用<em>pthread_mutex_lock</em>和<em>pthread_mutex_unlock</em>保护中间的代码，这一块代码被称作<strong>临界区(critical section)</strong>。如果需要销毁互斥锁，在使用<em>free</em>前还需要调用<em>pthread_mutex_destroy</em>。这样在其中一个线程进行累加值时，另一个线程会因为互斥锁阻塞。此时系统就能够将被阻塞的线程调度到等待区，并让另一个线程（可能是来自我们的程序，也有可能不是）使用空出的CPU。这样系统便能提升整体性能。</p>
<p>而另一种锁叫做自旋锁，它的用法只是将<em>pthread_mutex_t</em>类型的变量换成<em>pthread_spinlock_t</em>，然后把函数中的mutex换成spin给这个自旋锁初始化，加锁以及解锁。自旋锁与互斥锁的不同之处在于在使用互斥锁时系统能够即时地将被阻塞的线程调度等待队列直到锁被释放，而自旋锁则会在系统分配给当前线程的时间用尽前继续占用CPU，也就是说自旋锁仅仅是保护了临界区而不会让CPU资源被释放。这样看起来自旋锁没有存在的必要，但是如果我们仅仅是对高速存储器（如内存）中的一个数据结构进行修改事实上线程只需要几百纳秒时间就可以读写完毕，此时等待自旋锁的线程可以立刻继续对同一个数据结构进行读写，而让系统调度线程可能会花上几十甚至几百毫秒时间，因此在这种情况下自旋锁的效率要比互斥锁高得多。但我们平时写代码时并不需要关心使用自旋锁还是互斥锁，因为大部分操作系统的互斥锁都会先自旋一段时间，只有超出规定的等待时间才会变成真正的互斥锁。因此我们平时完全不用担心使用哪一种锁，全部使用互斥锁就好了。</p>
<p>我们现在知道使用锁能够提升系统的性能，但是提升系统的性能并不等于提升我们程序的性能。此时我们的程序虽然有两个线程，但事实上在任何时候都只有一个线程在工作（因为互斥锁保护了线程中的每一个指令），而且由于加锁和上下文切换的开销这样一个程序会比单线程程序还慢。因此互斥锁的最佳工作环境是在执行耗时任务的线程中保护写入同一数据结构的一刻，这样在其中一个线程写入数据时，其他线程可以继续忙于自己的工作直到需要写入数据为止。多线程下载基本就是这样工作的。</p>
<p>现在多线程看上去非常简单，只需要在适当的时机加锁解锁就可以了。但在大型系统中我们会遇到很多问题，其中最常见的一个便是死锁(dead-lock)。死锁是什么意思呢？我们来举个例子。现在如果有两个数据结构A和B需要给不同线程读写，每个线程都需要能够读写这两个数据结构。我们可以用同一把锁给两个数据结构同时锁上并让一个线程在上面操作，但很明显这样效率太低，因为在一个线程修改A时另一个线程完全可以修改B。所以我们引入了第二把锁，用不同的锁锁住不同的数据结构。</p>
<p>这样听上去没有任何问题，但事实上真的如此吗？我们来看一个并发问题上的经典例子，叫哲学家就餐问题。</p>
<p>这个问题假设有五名哲学家围坐在一个餐桌旁，桌上同时放着五根筷子。哲学家的日常生活只有两件事：吃饭和思考人生。他们会随机思考一段时间，然后拿起他的左手和右手边的筷子吃饭（即操作共享数据），再放下筷子思考人生（即进行其他任务）。下面这张图表示了这五个哲学家和筷子的情况。</p>
<img src="/blog/2018/08/08/线程与协程-并发的魔法/philosopher.png">
<p>我们尝试用代码模拟一下这个场景</p>
<pre><code>#include &lt;stdio.h&gt;
#include &lt;pthread.h&gt;
#include &lt;unistd.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;time.h&gt;

void* eat(int id);
void* think(int id);
void* philosophy(void* id);
static pthread_mutex_t chopsticks[5];

int main() {
	srand((int)time(0));
	//初始化所有筷子
	pthread_mutex_init(&amp;chopsticks[0], NULL);
	pthread_mutex_init(&amp;chopsticks[1], NULL);
	pthread_mutex_init(&amp;chopsticks[2], NULL);
	pthread_mutex_init(&amp;chopsticks[3], NULL);
	pthread_mutex_init(&amp;chopsticks[4], NULL);
	//创建哲学家线程
	pthread_t philosopher1, philosopher2, philosopher3, philosopher4, philosopher5;
	const int id[5] = {0,1,2,3,4};
	pthread_create(&amp;philosopher1, NULL, philosophy, (void*)&amp;id[0]);
	pthread_create(&amp;philosopher2, NULL, philosophy, (void*)&amp;id[1]);
	pthread_create(&amp;philosopher3, NULL, philosophy, (void*)&amp;id[2]);
	pthread_create(&amp;philosopher4, NULL, philosophy, (void*)&amp;id[3]);
	pthread_create(&amp;philosopher5, NULL, philosophy, (void*)&amp;id[4]);
	pthread_join(philosopher1, NULL);
	pthread_join(philosopher2, NULL);
	pthread_join(philosopher3, NULL);
	pthread_join(philosopher4, NULL);
	pthread_join(philosopher5, NULL);
}

void* eat(int id) {
	//先申请右手边筷子，再申请左手边筷子
	if(id == 0) {
		pthread_mutex_lock(&amp;chopsticks[0]);
		pthread_mutex_lock(&amp;chopsticks[1]);
	} else if(id == 4) {
		pthread_mutex_lock(&amp;chopsticks[4]);
		pthread_mutex_lock(&amp;chopsticks[0]);
	} else {
		pthread_mutex_lock(&amp;chopsticks[i]);
		pthread_mutex_lock(&amp;chopsticks[i+1]);
	}
	printf(&quot;philosopher %d starts eating\n&quot;, id);
	sleep(rand()%30); //吃0-30秒饭
	//按照加锁顺序释放筷子
	if(id == 0) {
		pthread_mutex_unlock(&amp;chopsticks[0]);
		pthread_mutex_unlock(&amp;chopsticks[1]);
	} else if(id == 4) {
		pthread_mutex_unlock(&amp;chopsticks[4]);
		pthread_mutex_unlock(&amp;chopsticks[0]);
	} else {
		pthread_mutex_unlock(&amp;chopsticks[i]);
		pthread_mutex_unlock(&amp;chopsticks[i+1]);
	}
	printf(&quot;philosopher %d has had meal\n&quot;, id);
	return NULL;
}

void* think(int id) {
	printf(&quot;philosopher %d starts thinking\n&quot;, id);
	sleep(rand()%60); //随机思考0-60秒
	return NULL;
}

void* philosophy(void* id) {
	int rid = *((int*)id);
	printf(&quot;philosopher %d started\n&quot;, rid);
	while(1) { //线程内无限循环
		think(rid); //先思考一段时间
		eat(rid); //然后吃饭
	}
}
</code></pre>
<p>编译运行这个程序，它会在一定时间内正常运行（这个时间可能会从几小时到几周甚至几个月不等，全凭你的运气），但总有一刻它会卡住不动，也就是在所有哲学家都同时决定吃饭而且同时拿起右手边筷子的时候。不要认为这种事很难发生，多线程编程总是会遵循墨菲定律，也就是最坏的情况一定会发生。在计算机每秒计算上千万乃至上亿次的情况下，一切都有可能发生。在这种情况下，我们就遇到了死锁。死锁的解决方案多种多样，可以从逻辑上来解决，比如在申请到右手边筷子但无法申请左手边筷子的时候，主动放弃右手的筷子。互斥锁和自旋锁有一个特殊的函数<em>pthread_mutex_trylock</em>和<em>pthread_spin_trylock</em>。这两个函数会无阻塞地尝试获取锁并返回一个表示锁的状态的值。如果这个值是0就表示锁获取成功可以继续操作，否则会返回特定的errno错误码表示失败原因。这里我们可以配合trylock和sleep实现重试机制，如果重试几次后仍不能获取锁就放弃这次吃饭重新思考。因为这个机制比较常用，pthread有一个专门的<em>pthread_mutex_timedlock</em>函数，它可以接受一个超时时间，在超过等待时间后会返回ETIMEDOUT错误码。有一个术语用来表示这种超时等待锁的情况叫做活锁(livelock)。</p>
<p>但活锁仍不能完全解决资源浪费的问题，因此我们需要一些特殊的机制让进程能互相知道对方的状态，在使用锁之前就能获得关于锁的情况。幸运的是，操作系统为我们提供了这些工具，接下来我们看一看条件变量和信号量如何解决这个问题。</p>
<h3 id="03-条件变量"><a class="header-anchor" href="#03-条件变量">¶</a>03 条件变量</h3>
<p>在上一节中，我们看到如果我们在写代码时逻辑出现错误，互斥锁会引发死锁。这在大型系统中可能会导致整个系统卡死以至瘫痪。因此我们需要有一个线程间互相通信的机制，其中一个机制叫做条件变量。条件变量给互斥锁加上一个特别的功能，它能够让等待这把锁的线程被其他线程唤醒并检查是否满足自己需要的条件。如果条件满足，这个线程就可以操作数据然后继续进行其他任务，如果不满足，这个线程就会休眠，将CPU让给其他线程。</p>
<p>我们看一看条件变量是如何解决死锁并提高程序的并发量的。</p>
<pre><code>#include &lt;stdio.h&gt;
#include &lt;pthread.h&gt;
#include &lt;unistd.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;time.h&gt;
#include &lt;stdbool.h&gt;

void* eat(int id);
void* think(int id);
void* philosophy(void* id);
pthread_cond_t cond;
pthread_mutex_t table;
bool eating[5] = {false,false,false,false,false};

int main() {
	srand((int)time(0));
	pthread_mutex_init(&amp;table, NULL);
	pthread_cond_init(&amp;cond, NULL);
	//创建哲学家线程
	pthread_t philosopher1, philosopher2, philosopher3, philosopher4, philosopher5;
	const int id[5] = {0,1,2,3,4};
	pthread_create(&amp;philosopher1, NULL, philosophy, (void*)&amp;id[0]);
	pthread_create(&amp;philosopher2, NULL, philosophy, (void*)&amp;id[1]);
	pthread_create(&amp;philosopher3, NULL, philosophy, (void*)&amp;id[2]);
	pthread_create(&amp;philosopher4, NULL, philosophy, (void*)&amp;id[3]);
	pthread_create(&amp;philosopher5, NULL, philosophy, (void*)&amp;id[4]);
	pthread_join(philosopher1, NULL);
	pthread_join(philosopher2, NULL);
	pthread_join(philosopher3, NULL);
	pthread_join(philosopher4, NULL);
	pthread_join(philosopher5, NULL);
}

void* eat(int id) {
	pthread_mutex_lock(&amp;table); //使用条件变量前需要先给条件变量关联的锁上锁
	//检查左右的哲学家是否在进食，如果是阻塞就等待条件变量唤醒
	if(id == 0) {
		while(eating[4] || eating[1]) {
			pthread_cond_wait(&amp;cond, &amp;table);
		}
	} else if(id == 4) {
		while(eating[0] || eating[3]) {
			pthread_cond_wait(&amp;cond, &amp;table);
		}
	} else {
		while(eating[id-1] || eating[id+1]) {
			pthread_cond_wait(&amp;cond, &amp;table);
		}
	}
	eating[id] = true; //标识这个哲学家正在吃饭
	pthread_mutex_unlock(&amp;table);
	printf(&quot;philosopher %d starts eating\n&quot;, id);
	sleep(rand()%30); //吃0-30秒饭
	printf(&quot;philosopher %d has had meal\n&quot;, id);
	return NULL;
}

void* think(int id) {
	eating[id] = false; //标识这个哲学家吃饭结束开始思考
	pthread_mutex_lock(&amp;table);
	pthread_cond_signal(&amp;cond); //通知其他线程重新检查条件变量
	pthread_mutex_unlock(&amp;table);
	printf(&quot;philosopher %d starts thinking\n&quot;, id);
	sleep(rand()%60); //随机思考0-60秒
	return NULL;
}

void* philosophy(void* id) {
	int rid = *((int*)id);
	printf(&quot;philosopher %d started\n&quot;, rid);
	while(1) { //线程内无限循环
		think(rid); //先思考一段时间
		eat(rid); //然后吃饭
	}
}
</code></pre>
<p>这个版本的哲学家进餐问题不再使用五个筷子作为锁，取而代之的是一个名叫table的锁。我们声明了一个bool类型的数组用来记录哲学家是否在进餐状态。假如一个哲学家想要进餐，他会先使用<em>pthread_mutex_lock</em>锁住桌子，检查左右两侧的哲学家是否在进餐状态。假如左右两侧哲学家都没有进餐，说明两侧的筷子都是可用的，这时哲学家会解锁桌子，将自己的吃饭状态改为true，进餐一段时间后再回到思考状态，将进餐状态改为false，使用<em>pthread_cond_signal</em>通知其他哲学家重新检查进餐条件。如果左右两侧有任何一侧在进餐，那么这个哲学家会使用<em>pthread_cond_wait</em>等待其他线程改变条件变量。这样由于整个程序只有一把锁和一个条件变量，不仅不会死锁还因为无需等待其他哲学家让出筷子效率更高。</p>
<p>在调用任何与条件变量有关的函数前，线程都需要获取条件变量相关联的锁。这是因为条件变量本身也是一个共享变量，同样需要锁保护。在<em>pthread_cond_wait</em>内部，函数会将释放锁，等待唤醒。在接到唤醒信号后，<em>pthread_cond_wait</em>会重新获得锁然后返回，但是这个函数返回并不代表条件一定会满足，因此我们在这里使用一个while循环，让线程重新检查条件变量，如果不满足继续阻塞。这也是为什么我们不需要在while循环调用<em>pthread_cond_wait</em>前重新加锁的原因。在条件满足后，线程使用<em>pthread_mutex_unlock</em>解开<em>pthread_cond_wait</em>获得的锁，然后继续执行接下来的代码。执行完毕后，线程在talbe锁保护的临界区内使用<em>pthread_cond_signal</em>通知其他阻塞的线程重新检查条件。需要注意的是<em>pthread_cond_signal</em>在标准内之规定的是至少要通知一个线程，根据实现不同这个函数可以通知一个或多个正在等待的线程。如果需要通知所有线程则需要使用<em>pthread_cond_broadcast</em>函数。但要小心的是如果有很多线程使用同一个条件变量，<em>pthread_cond_broadcast</em>会导致大量时间被用在加锁和解锁上，因此要谨慎使用。</p>
<p>现在我们知道了其中一个让线程同步避免死锁的方法，下面我们看看另一个机制————信号量。</p>
<h3 id="04-信号量"><a class="header-anchor" href="#04-信号量">¶</a>04 信号量</h3>
<p>在上一节我们认识到条件变量配合互斥锁可以让线程得到一个检查其他线程状态的机会。在某种意义桑来说，信号量能够做的事情更多，它可以存储一个表明有多少空闲资源值。使用信号量时我们不需要再使用互斥锁，只需要申请一个信号量便可以让进程中的每个线程等待信号量有足够的资源供线程使用。但这并不是信号量最原始的用途。事实上，信号量最大的用途是在不同进程间同步，因为信号量可以在内核或者文件中存储，这样即使是不共享内存的多进程程序也能够在获取共享资源（比如文件系统）时同步了。因此实际上信号量是一种IPC(Inter-Process Communication)机制。由于信号量在不同的系统上实现并不一致（例如在Mac OS X上苹果实现了自己的无名信号量并将POSIX的无名信号量标记为废弃的），而且平时线程同步中也不会用到它，在这里我不会特别举例，只是大概讲解它的用法。如果感兴趣的话可以自行查阅自己系统上信号量的用法。</p>
<p>在我们现在的Unix系统或类Unix系统中事实上存在着两种截然不同的信号量机制，一种是较老的XSI信号量（也称作SYSTEM V信号量），主要用于进程同步，它的操作方法较为复杂而且有不安全之处，因此我们不在这里详细讲解。而另一种则是较新的POSIX信号量，它的API更为简单，而且同时适合线程和进程同步.</p>
<p>与锁不同的是，POSIX信号量的头文件为semaphore.h，XSI信号量则为sys/sem.h。POSIX信号量根据存储位置分为两种：无名信号量和有名信号量。无名信号量存储在内存中，生命周期与创建它的进程一致，随进程结束而消失；而有名信号量则存储在文件中，生命周期与内核一致，只要仍有进程在使用它那么它就不会被销毁。而根据信号量存储的值也有两种不同的信号量：二元信号量(binary semaphore)和计数信号量(record semaphore)。二元信号量就和互斥锁一样，1表示资源可用，0表示资源被锁住。而计数信号量则有一个具体的值表明信号量所代表的资源还有多少可用。这两种信号量在申请时并没有明确的界限，只是单纯的使用方法不同。由此可见，我们可以用二元信号量模拟一个互斥锁或者用计数信号量管理一个资源池。无名信号量使用<em>sem_init</em>开启，<em>sem_destroy</em>销毁。线程有两个不同的函数可以用来操作信号量：<em>sem_wait</em>（又称作P操作，源自荷兰语Proberen，等待）和<em>sem_post</em>（又称作V操作，源自荷兰语Verhogen，增加）。与互斥锁一样，信号量也有一个非阻塞的函数<em>sem_trywait</em>。这个函数可以尝试获取信号量，如果获取失败则返回-1，并将errno设为EAGAIN。而有名信号量则使用<em>sem_open</em>开启，因为它是在文件系统上操作的所以在销毁时也要像关闭文件一样先调用<em>sem_close</em>关闭信号量再调用<em>sem_unlink</em>销毁信号量。在操作信号量时有名信号量和无名信号量使用同一组函数。如果要使用信号量解决哲学家进餐问题只需要使用5个信号量模拟筷子，再使用一个信号量模拟一把互斥锁保护获取筷子的过程即可。具体代码大家可以自己尝试实现一下。</p>
<h2 id="0x02-使用协程提高程序效率"><a class="header-anchor" href="#0x02-使用协程提高程序效率">¶</a>0x02 使用协程提高程序效率</h2>
<p>在上面我们介绍了如何使用系统的线程机制实现多线程应用，但是认真读下来我们会发现实际介绍多线程的只有短短的一节，剩下的都是在讲怎么在多线程应用中保护共享数据不被破坏以及防止死锁的发生。但这些机制或多或少都有因为编码失误导致数据错误的风险。那么有没有什么能够让我们尽可能地减少甚至杜绝破坏共享数据和死锁的问题的方法呢？答案是肯定的。下面我们就来介绍一下协程(coroutine)是如何解决这些问题的。</p>
<p>在刚刚介绍的线程中，线程调度完全由系统控制，这不仅使用起来麻烦，还会带来上下文切换的开销。更不用说在实际编程中需要解决的种种锁和竞态条件的问题。因此在我们常用的大部分语言中都提供了另一种机制————协程。协程可以被看作是一种轻量级的线程，它被称作协程是因为它的目的是和主程序协同完成工作。它与上文的线程不同的是它并不是由操作系统控制，而是由我们编写的程序本身控制。因此使用协程并不会有像系统线程那样大的上下文切换的开销。在使用系统线程和锁时，由于我们不能控制操作系统选择哪些线程在CPU上运行，很多我们空出的CPU时间实际上是被其他程序的线程消耗。而同一个系统线程则可以运行很多协程，如果其中一个协程因为等待IO被挂起，我们随时都可以选择另一个等待中的协程运行而不用担心系统开销。我们常用的语言都有自己的协程实现，有的是语言内建的特性，比如ython，golang，erlang等都有自己的协程实现；有的则是使用其他库实现的，比如java，C，C++都有比较成熟协程库，甚至很多C程序员有着自己的协程实现。下面我们来看一看常用的几种协程模型————生成器(generator或semicoroutine)，actor和CSP。这些被称作模型是因为它们没有特定的实现，但是这些实现都有共通之处。而actor和CSP模型则更是有严谨的数学理论证明它们是正确且通用的并发模型。协程是异步编程技术的一部分，由于这一章主要是介绍协程如何提高效率，我们不会涉及包括回调和Promise等的其他常用的异步编程技术。</p>
<h3 id="基于生成器的协程-以python为例"><a class="header-anchor" href="#基于生成器的协程-以python为例">¶</a>基于生成器的协程（以Python为例）</h3>
<p><em>本节中所有代码都基于Python3.6编写，在Python3.5以下的版本将不能使用后文讲的await/async，在Python3.4以下将不能使用yield from实现协程（Python原生的协程在Python3.4才有正式实现），因此请务必使用至少Python3.4以上的版本。</em></p>
<h4 id="生成器简介"><a class="header-anchor" href="#生成器简介">¶</a>生成器简介</h4>
<p>我们要接触的第一种协程类型是由Python，C#，lua和javascript采用的基于生成器的协程。生成器协程是一个比较难懂的概念（不幸的是Python让它更难懂了点），一部分原因是生成器一开始并不是为了协程，而只是为了简化迭代器(iterator)的编写而生的。这也是为什么generator被称作semicotoutine（半协程）的原因。它并不是模拟了系统内部使用的线程管理器和轻量级线程的机制，而是实现了一个能够在不同的协程和主程序之间来回跳转的机制（有一个专门的术语Asymmetric coroutines 非对称协程用来描述这种结构）。这种理论和术语听起来的确有些难懂，我们还是看一看代码来理解这个机制。首先，我们来认识一下生成器。不严谨地说，生成器指的是一种特殊的函数，它可以在运行途中暂停，被主程序重新调用，并产出(yield)新的返回值。在重新调用的途中主程序也可以传入新的值并让生成器根据这个值产出返回值。下面我们在控制台使用Python REPL环境运行一段简单的生成器代码。</p>
<p>一个简单的生成器</p>
<pre><code>def simplegen():
    print(&quot;gererator started&quot;)
    yield &quot;hello&quot;
    yield &quot;world&quot;
    print(&quot;generator stopped&quot;)
</code></pre>
<p>我们直接调用一下这个生成器，会得到</p>
<blockquote>
<p>&gt;&gt;&gt; simplegen<br>
&gt;&gt;&gt; &lt;function simplegen at 0x102a23668&gt;<br>
&gt;&gt;&gt; simplegen()<br>
&gt;&gt;&gt; &lt;generator object simplegen at 0x102a13aa0&gt;</p>
</blockquote>
<p>这样类似的信息，说明simplegen是一个函数，但不是普通的函数，而是一个生成器的工厂函数<br>
现在我们从这个工厂函数获取一个生成器对象，然后使用Python的<em>next</em>函数或者直接在生成器对象上调用*#next*方法</p>
<blockquote>
<p>&gt;&gt;&gt; g = simplegen()<br>
&gt;&gt;&gt; next(g)<br>
&gt;&gt;&gt; gererator started<br>
&gt;&gt;&gt; ‘hello’<br>
&gt;&gt;&gt; g.next()<br>
&gt;&gt;&gt; ‘world’<br>
&gt;&gt;&gt; g.next()<br>
&gt;&gt;&gt; generator stopped<br>
&gt;&gt;&gt; Traceback (most recent call last):<br>
&gt;&gt;&gt;   File “<stdin>”, line 1, in <module><br>
&gt;&gt;&gt; StopIteration</module></stdin></p>
</blockquote>
<p>我们会发现，调用next后，生成器执行了print代码并产出了第一个yield的值，然后就停止执行；直到我们第二次调用next后生成器才产出第二个yield后的值后停止执行。在我们第三次调用生成器时，生成器已经产出全部值，所以它执行了最后一行代码，并抛出了StopIteration错误（这是Python标志迭代停止的标准方式）。在StopIteration错误抛出后，这个生成器便没有用了，我们需要重新获取一个生成器执行。</p>
<h4 id="从生成器到协程"><a class="header-anchor" href="#从生成器到协程">¶</a>从生成器到协程</h4>
<p>由此可见，生成器会在yield前停下，产出yield后的值，然后等待主程序的下一次调用。但是生成器不仅仅能产出值，它还能接受值。下面看一个稍微复杂一些的例子。</p>
<p>一个稍微复杂一些的使用生成器的例子</p>
<pre><code>def hardergen():
    print(&quot;generator started&quot;)
    x = yield
    print(&quot;generator received &quot; +x)
    print(&quot;generator stopped&quot;)
</code></pre>
<p>我们使用生成器对象的*#send*方法给生成器发送一个值</p>
<blockquote>
<p>&gt;&gt;&gt; g = hardergen()<br>
&gt;&gt;&gt; g.send(5)<br>
&gt;&gt;&gt; Traceback (most recent call last):<br>
&gt;&gt;&gt;   File “<stdin>”, line 1, in <module><br>
&gt;&gt;&gt; TypeError: can’t send non-None value to a just-started generator</module></stdin></p>
</blockquote>
<p>Python并没有像我们预想的那样打印出接受到的数字，反而抛出了一个TypeError。这是Python的生成器实现导致的问题。因为Python生成器会在yield前停止运行并产出值，而接受值则要等到下一次调用时才能传入yield的位置。因此Python需要先启动一次生成器，让它运行到第一次接受值的位置，然后才能正确得到我们传入的值，这个过程叫做预激。</p>
<blockquote>
<p>&gt;&gt;&gt; g = hardergen()<br>
&gt;&gt;&gt; g.send(None)<br>
&gt;&gt;&gt; generator started<br>
&gt;&gt;&gt; g.send(5)<br>
&gt;&gt;&gt; generator received 5<br>
&gt;&gt;&gt; generator stopped<br>
#省去StopIteration错误信息</p>
</blockquote>
<p>我们再回想一下协程不精准的定义：如果主程序能够控制另一个程序协同工作，那么这个程序就能被称作协程。在这里我们通过给生成器传入一个值让它能够在主程序的要求下将它打印出来，而且这个生成器何时运行是由主程序控制的，因此在这里我们也就创造出了一个非常简单的协程。</p>
<p>这个协程看起来没有任何用处，它只能运行一次，打印一个值后就完全退出了。为了能让协程持续运行，我们需要在协程内部引入一个循环。下面我们来看一个使用协程计算平均值的例子（本例子来自流畅的Python，稍有改动）。</p>
<pre><code>def averager():
    average = 0.0
    count = 0
    print(&quot;start averager&quot;)
    while True:
        x = yield average
        count += 1
        average = ((average*(count-1)) + x) / count
</code></pre>
<p>下面我们来测试一下这个协程</p>
<blockquote>
<p>&gt;&gt;&gt; a = averager()<br>
&gt;&gt;&gt; a.send(None) #预激协程<br>
&gt;&gt;&gt; start averager<br>
&gt;&gt;&gt; 0.0<br>
&gt;&gt;&gt; a.send(5)<br>
&gt;&gt;&gt; 5.0<br>
&gt;&gt;&gt; a.send(4)<br>
&gt;&gt;&gt; 4.5</p>
</blockquote>
<p>现在我们有了一个随时都可以被重新利用的协程。只要程序中遇到需要计算平均值的地方，我们就可以使用这个协程帮助我们计算了。现在我们已经有了使用基于生成器的协程编写并发程序的基础，接下来只需要使用一个事件循环驱动所有的协程，并仔细编写协程让它能够在遇到耗时操作时使用yield将控制权返回事件循环，等待下一个事件触发协程运作。这便是一种简单的事件驱动模型(Event Driven Model)。我们模拟一个web服务器看看怎样用协程完成事件驱动模型。</p>
<pre><code>def get(id):
    yield &quot;coroutine&quot; + str(id) + &quot; started&quot;
    while True:
        image = yield &quot;start to wait for reading an image&quot; #模拟等待系统读取图片
        yield (&quot;the image is &quot; + image)
</code></pre>
<p>下面我们来从控制台模拟请求这个服务器的资源</p>
<blockquote>
<p>&gt;&gt;&gt; coroutines = [get(i) for i in range(10)] #创建一个协程池<br>
&gt;&gt;&gt; [c.send(None) for c in coroutines] #预激所有协程<br>
&gt;&gt;&gt; [‘coroutine0 started’, ‘coroutine1 started’, …]<br>
&gt;&gt;&gt; coroutines[0].send(None) #模拟一个请求，这里用None驱动协程到下一个yield等待系统IO返回<br>
&gt;&gt;&gt; ‘start to wait for reading an image’<br>
&gt;&gt;&gt; coroutines[1].send(None) #在0号协程等待图片时其他协程可以继续接受请求<br>
&gt;&gt;&gt; ‘start to wait for reading an image’<br>
&gt;&gt;&gt; coroutines[0].send(“hello.jpg”) #模拟系统IO事件，触发0号协程继续处理<br>
&gt;&gt;&gt; ‘the image is hello.jpg’<br>
&gt;&gt;&gt; coroutines[0].send(“None”) #此时0号协程已经处理完一个请求，可以继续接受下一个请求<br>
&gt;&gt;&gt; ‘start to wait for reading an image’</p>
</blockquote>
<p>这样，同一个线程可以在等待读取图片的同时继续接受请求，并在读取到图片后再将数据返回给用户。当然在这里我们使用控制台输入模拟了用户请求和异步IO，实际上这些是由操作系统内核给线程发送信号的。好在我们并不需要自己处理异步IO信号，只需要使用从Python3.4开始提供的asyncio包就可以了。但在使用它之前，我们还要认识另一个语法结构————yield from。</p>
<h4 id="使用yield-from阻塞协程"><a class="header-anchor" href="#使用yield-from阻塞协程">¶</a>使用yield from阻塞协程</h4>
<p>yield from原本的作用是通过一个生成器连接主程序和另一个生成器。在实际运用中，生成器在执行耗时操作时可能是在调用另一个生成器（称作子生成器 subgenerator），而子生成器需要主程序给它传参数，yield from可以让主程序直接和子生成器通信。此时使用yield from的生成器本身就成为一个委派生成器(delegated generator)在yield from处阻塞，将控制权转让给主程序，直到子生成器结束运行后再恢复。但asyncio中yield from的用法类似于线程中的join函数，主程序和协程都不关心子生成器产出的值，只需要子生成器本身运行后再执行协程。此时yield from可以让事件循环接手继续排定其他协程，直到子生成器运行结束后让被阻塞的协程恢复。这在其他语言里使用了更加简洁的await来表示。</p>
<p>由于这篇教程不是讲述Python的用法，我们直接看一看yield from在协程中的作用。</p>
<h4 id="使用asyncio实现协程"><a class="header-anchor" href="#使用asyncio实现协程">¶</a>使用asyncio实现协程</h4>
<p>在真正的基于生成器的协程中，大部分语言使用了两个关键字————async和await。在Python3.4下这两个关键字分别被一个装饰器 @asyncio.coroutine和关键字yield from代替，而Python3.5也已经引入了async和await关键字。下面来看一个简单的例子。</p>
<pre><code>@asyncio.coroutine #这是Python的装饰器，效果和获取asyncio.coroutine(slow_function)的返回值相同，用来表明这是一个协程
def slow_function(): 
    yield from asyncio.sleep(3) #等待3秒，模拟IO操作，yield from能够将控制权还给事件循环，使用asyncio.sleep而不是time.sleep防止阻塞整个线程
    return 42

@asyncio.coroutine
def async_function():
    i = 0
    while True:
        print(i, flush=True,end=&quot; &quot;) #小技巧，输出不换行，并每次都刷新缓冲区
        i += 1
        try:
            yield from asyncio.sleep(.1) #协程只有在yield处才能退出，因此使用yield查看状态
        except asyncio.CancelledError: #如果捕获到Cancelled错误就退出协程
            print(&quot;async_function cancelled&quot;, flush=True)
            break

def main():
    asyncf = asyncio.async(async_function())
    result = yield from slow_function()
    asyncf.cancel()
    return result
</code></pre>
<p>我们来测试一下这个协程</p>
<blockquote>
<p>&gt;&gt;&gt; loop = asyncio.get_event_loop() #协程使用asyncio包提供的事件循环驱动<br>
&gt;&gt;&gt; result = loop.run_until_complete(main()) #主函数注册到事件循环，事件循环会驱动主程序中调用的协程<br>
&gt;&gt;&gt; 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 async_function cancelled<br>
&gt;&gt;&gt; loop.close() #事件循环结束后停止循环<br>
&gt;&gt;&gt; print(result)<br>
&gt;&gt;&gt; 42</p>
</blockquote>
<p>在slow_function因为等待IO操作阻塞时，协程并没有停止运作，而是由事件循环驱动async_function打印出数字。最后asyncf.cancel会从async_function的yield位置抛出一个Cancelled错误，协程可以捕获它然后退出（或者甚至拒绝退出）。对于lua和javascript来说，协程启动后是不能退出的。而C#则可以使用特殊的函数退出或者像Python一样设置一个特定的值然后break退出。在这里我们使用了asyncio.sleep而不是time.sleep是因为time.sleep会导致当前线程直接挂起，而协程实际是单线程程序，如果挂起当前线程整个事件循环都会停止。</p>
<p>在Python3.6中，Python已经引入了其他语言常用的async和await替代了asyncio.coroutine装饰器和tield from语法，因此上面的例子可以改写成以下形式。</p>
<pre><code>async def slow_function(): #使用async关键字定义协程
    await asyncio.sleep(3) #等待3秒，模拟IO操作，await能够将控制权还给事件循环，使用asyncio.sleep而不是time.sleep防止阻塞整个线程
    return 42

async def async_function():
    i = 0
    while True:
        print(i, flush=True,end=&quot; &quot;) #小技巧，输出不换行，并每次都刷新缓冲区
        i += 1
        try:
            await asyncio.sleep(.1) #使用await替换yield，错误会在await处抛出
        except asyncio.CancelledError: #如果捕获到Cancelled错误就退出协程
            print(&quot;async_function cancelled&quot;, flush=True)
            break

async def main():
    asyncf = asyncio.ensure_future(async_function()) #由于async声明的不是生成器，在这里使用
    result = await slow_function()
    asyncf.cancel()
    return result
</code></pre>
<blockquote>
<p>&gt;&gt;&gt; loop = asyncio.get_event_loop()<br>
&gt;&gt;&gt; result = loop.run_until_complete(asyncio.ensure_future(main()))<br>
&gt;&gt;&gt; 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 async_function cancelled<br>
&gt;&gt;&gt; print(result)<br>
&gt;&gt;&gt; 42</p>
</blockquote>
<p>在这里我们使用把main函数也声明为一个协程，因为await只有在协程中才能使用。另外asyncio.async也被替换成了asyncio.ensure_future。asyncio.ensure_future的作用和asyncio.async类似，都是将协程加入事件循环，但是asyncio.async已经被废弃了，如果在以上代码中使用asyncio.async的话Python会报Syntax Error错误。除此以外async/await还是大大简化了语法结构，也使程序更佳易读。</p>
<p>如果想进一步了解Python的协程，推荐阅读：流畅的Python（[巴西]Luciano Ramalho著 人民邮电出版社出版），Python Cookbook第三版（Alex Martelli / David Ascher著 人民邮电出版社出版）</p>
<p>讲到现在，我们终于讲完了基于生成器的协程，接下来我们会看到一个更佳直观的并发模型————Actor模型。</p>
<h3 id="基于actor模型的协程-以erlang为例"><a class="header-anchor" href="#基于actor模型的协程-以erlang为例">¶</a>基于Actor模型的协程（以Erlang为例）</h3>
<p><em>本节所有代码基于Erlang/OTP 20。尽管Erlang与本节相关的核心功能应当没有发生变化，但还是推荐使用Erlang/OTP 20及更高版本测试</em></p>
<h4 id="actor和erlang简介"><a class="header-anchor" href="#actor和erlang简介">¶</a>Actor和Erlang简介</h4>
<p>Actor模型是一个便于理解且便于编写的并发模型，因此很多没有协程功能的语言都实现了一个基于Actor模型的并发库。Actor模型本身历史悠久，1973年就有了完整的论文证明它的有效性。而今天我们要看的这门语言是第一款大规模在生产环境下使用Actor模型的语言————Erlang。Erlang在1986年由Joe Armstrong发明，本来是为了解决爱立信交换机高并发的问题，因此它自带一个庞大的叫做OTP的标准库。它的并发能力极高，WhatsApp使用Erlang在一台双X5675CPU搭配64G内存的服务器上就达到了200万并发。这就是Actor模型提供的轻量协程的魅力所在。不过Erlang是一门函数式语言，因此语法和我们平时用到的会有诸多不同之处。我会在必要的时候讲解语句的功能，并且尽可能将我们用到的Erlang功能压缩到最小，确保突出Actor模型本身的特性。</p>
<p>Actor模型可以和现实生活做类比。在现实生活中，每个人都可以在同一时刻做不同的工作，而且互相之间不会共享脑电波或者共用一个大脑（如果真的那样就太可怕了）。如果我想要改变你对一件事的认知，我可以给你发一条消息（比如对话，电子邮件，或者任何一个人类之间能传递消息的方式）。但我并不知道你有没有真的听到了我说的话或者看到我发的消息，因此我可能会问你问题或者观察你的反应才知道你有没有收到我的消息。Actor模型也是如此。在Actor模型中，每一个协程被称作Actor，Actor由语言提供的上下文管理器控制，从表面上来看如果一个Actor阻塞另一个Actor会被切换到CPU上执行，因此不同Actor可以看作是在同一时刻工作的。每个Actor都有自己的私有内存空间，它们之间通过发送消息而不是共享内存来交流。这些消息是不保证递送的，也就是说一个Actor只有通过接收回执或者类似的方法才能得知它的消息有没有被收到。Actor的工作环境基本就像公司中的公共办公区，每个Actor都在独立做自己的事，但有一点不同的是Actor在临死（崩溃）前会发出自己的最后一条消息说明自己死亡原因。比如“我是因为有人要我除以零而死的”。现在这个办公区里有一部分特殊的Actor被称作监督者(supervisor)，每个监督者都会管理一部分真正干活的Actor，称作工人(worker)。当worker发出死亡原因时，监督者可以捕捉到这个消息，然后重启这个工人，或者重启自己管理的其他工人，甚至可以让自己崩溃来通知上一级的监督者。Actor模型简单的说就是一个由监督者管理，工人干活的树状网络结构，其中每一个Actor有着自己的内存空间，在适当的时候被程序本身而不是系统调度到CPU上工作。与上文基于生成器的协程不同，Actor模型模拟了系统调度线程的机制，只不过线程变成了更轻巧的协程，而系统的调度器变成了语言实现本身的协程管理器。这种结构被称作Symmetric coroutines 对称协程。</p>
<p>说了这么多介绍，下面我们看一看Erlang到底是怎么实现Actor模型的。</p>
<h4 id="erlang：天生并发"><a class="header-anchor" href="#erlang：天生并发">¶</a>Erlang：天生并发</h4>
<p>很多语言都会将Actor模型作为某个包提供给用户，但Erlang由于原本的需求就是解决交换机的并发问题，它的语言和虚拟机本身就实现了协程并发，并且虚拟机会自动分配Erlang协程到计算机每一个可用的CPU核心，因此在Erlang上开始学习并发是非常简单的，我们使用erl打开Erlang的REPL环境，然后创建第一个Erlang协程（在Erlang官方手册中，这些协程被称作进程process，但实际上它们都是Actor，为了和全文一致我们在这里称Erlang中的进程为Erlang协程）。</p>
<blockquote>
<p>1&gt; Pid = spawn(io, format, [“hello world”]). %Erlang的变量名首字母必须大写，一句语句结束必须要有英文句号，用小写字母开头不加引号的字符则是原子。原子创建后不会被销毁，可以高效地被其他协程引用<br>
hello world&lt;0.73.0&gt;</p>
</blockquote>
<p>一个协程通过spawn函数创建，这个函数的第一个值是模块名，第二个值是方法名，第三个值是参数列表。就是这么简单，一个协程就被创建了。协程启动后立刻就会被执行，因此hello world就被打印出来了。而后面的&lt;0.73.0&gt;则是控制台自动打印出的这个协程的编号(pid)。由于控制台也是Erlang协程，在spawn后新的协程比控制台运行要更快，因此Pid会在hello world之后被打印出来。</p>
<p>接下来看一个实际一点的例子，我们自己编写一个程序，然后使用协程运行它。需要注意的是Erlang<strong>不支持</strong>在控制台中直接编写函数，这是Erlang的一个bug，因此我们要打开一个新文件，命名为xxx.erl，然后在里面写一个函数。</p>
<pre><code>-module(zipwith). %每一个Erlang函数都需要被包含在一个模块里
-export([zipWith/3]). %这一行表示我们要让zipWith函数对其他模块可见，没有export的函数不能在控制台或者其他模块中调用。/后面的数字是函数的元数，也就是参数数量。在Erlang中同名但参数数量不同的函数是不同的函数。

zipWith(_, [], _) -&gt; %这是模式匹配，只有符合模式的参数才能被这个函数子句识别，这里的模式是忽略第一和第三个参数，如果第二个参数为空则返回空列表
    []; %每个子句间用分号隔开
zipWith(_, _, []) -&gt; %这里的模式是忽略第一和第二个参数，如果第三个参数为空则返回空列表
    [];
zipWith(F, [Ha|Ta], [Hb|Tb]) -&gt; %否则这个函数期望在第一个参数是一个函数，第二和第三个参数是列表，[H|T]语法取出列表第一个元素放在H里，剩余的元素放在T里
    [F(Ha,Hb)|zipWith(F, Ta, Tb)]. %[A|L]表示把A拼接在L的最前面，由于函数式语言没有循环语句且对尾递归高度优化，这里使用递归循环处理这个列表。函数最后需要一个句号。
</code></pre>
<p>我们在控制台中使用一下zipWith/3函数，看看它有什么用</p>
<blockquote>
<p>1&gt; c(“zipwith.erl”). %和Java一样，Erlang程序需要先编译成字节码<br>
{ok,zipwith}<br>
2&gt; zipwith:zipWith(fun(A,B)-&gt;A+B end,[1,2,3],[2,3,4]). %这里的fun创建了匿名函数，接受两个参数，返回两个参数的和，刚好和我们在上面写的F(Ha,Hb)对应<br>
[3,5,7]</p>
</blockquote>
<p>我们可以看出，zipWith/3函数的作用是把两个列表的元素一一对应地应用一个指定的函数然后返回一个处理过的新列表。下面我们把这个函数变成一个Erlang协程。</p>
<pre><code>-module(zipwith).
-export([zipWith/0]). %在这里我们导出元数为0的zipWith函数，因为这个函数可以作为Erlang协程获取消息处理

zipWith() -&gt;
    receive %receive表明从这个协程的信箱中读取其他协程发来的信息
        {_, [], _} -&gt; %模式匹配信息，功能和原zipWith第一个子句相同
            io:format(&quot;[]&quot;), 
            zipWith(); %递归这个函数，让协程能够继续接收消息，功能与while(True)一致。信箱的匹配子句也要用分号隔开
        {_, _, []} -&gt; %功能与原zipWith第二个子句相同
            io:format(&quot;[]&quot;),
            zipWith();
        {F, [Ha|Ta], [Hb|Tb]} -&gt;
            io:format(&quot;~w~n&quot;,[[F(Ha, Hb)|zipWith(F, Ta, Tb)]]),%由于同名不同元数的函数属于不同的函数，这里我们仍然可以实现一个原版函数来辅助这个协程工作
            zipWith()
    end.
            
zipWith(_, [], _) -&gt; 
    []; 
zipWith(_, _, []) -&gt;
    [];
zipWith(F, [Ha|Ta], [Hb|Tb]) -&gt; 
    [F(Ha,Hb)|zipWith(F, Ta, Tb)]. 
</code></pre>
<p>我们在控制台测试一下这个协程</p>
<blockquote>
<p>1&gt; c(“zipwith”).<br>
{ok,zipwith}.<br>
2&gt; Pid = spawn(zipwith,zipWith,[]).<br>
&lt;0.67.0&gt;.<br>
3&gt; Pid ! {fun(A,B)-&gt;A+B end,[1,2,3],[2,3,4]}.<br>
[3,5,7]</p>
{#Fun<erl_eval.12.99386804>,[1,2,3],[2,3,4]} %这是控制台自动打印的协程接收到的消息，无需理会
</erl_eval.12.99386804></blockquote>
<p>我们使用spawn函数创建了一个Erlang协程，然后使用一个特殊的符号*!*给它发送了一个消息。这个感叹号叫做发送操作符。发送一个消息的标准做法是把消息体包裹在一个元组里。{}表示这是一个元组，元组可以存储任何Erlang类型，并且可以直接在协程内高效地进行模式匹配。我们传给这个协程的消息和给原版函数的参数是一样的，唯一不同的是现在zipWith/3函数变成了一个Erlang协程，而发送消息的方式则是对这个协程的Pid使用发送操作符。另一个需要注意的是我们把返回值改成了打印语句，因为协程是异步的，消息的发送方并不会期待其他协程给它返回结果，因此如果要从协程返回数据我们仍然需要使用消息。下面我们稍微改造一下zipWith/0函数，让它给控制台发送消息（不要忘了Erlang控制台本身也是Erlang协程）。</p>
<pre><code>%前后代码省略
zipWith() -&gt;
    receive 
        {From, {_, [], _ }} -&gt; %我们在这里接收一个发来这个消息的Erlang协程的Pid
            From ! [], %在当前协程处理完毕后把结果发到发送者的信箱
            zipWith(); 
        {From, {_, _, []}} -&gt;
            From ! [],
            zipWith();
        {From, {F, [Ha|Ta], [Hb|Tb]}} -&gt;
            From ![F(Ha, Hb)|zipWith(F, Ta, Tb)],
            zipWith()
    end.
</code></pre>
<p>现在我们调用这个Erlang协程的方式也要有些变化</p>
<blockquote>
<p>1&gt; c(zipwith).<br>
{ok,zipwith}<br>
2&gt; Pid = spawn(zipwith, zipWith, []).<br>
&lt;0.67.0&gt;<br>
3&gt; Pid ! {self(), {fun(A,B)-&gt;A+B end,[1,2,3],[2,3,4]}}.<br>
{&lt;0.60.0&gt;,{#Fun<erl_eval.12.99386804>,[1,2,3],[2,3,4]}}<br>
4&gt; receive Anything -&gt; %检查控制台自己的信箱<br>
4&gt; A<br>
4&gt; end.<br>
[3,5,7] %结果被正确地送到了控制台的信箱里</erl_eval.12.99386804></p>
</blockquote>
<p>self/0函数会返回当前协程的Pid，这样zipWith/3中就可以直接把处理完毕的消息异步地发送给控制台。控制台可以使用receive接收消息。如果一个Erlang协程的信箱里没有消息，这个协程会在receive处阻塞。因此合理使用消息可以在不同的Erlang协程间同步。</p>
<h4 id="actor模型的错误处理"><a class="header-anchor" href="#actor模型的错误处理">¶</a>Actor模型的错误处理</h4>
<p>Actor模型的强大不只是表现在它将并发问题抽象成不同的Actor协作，还体现在Actor之间可以互相连接。正如前文所提到的，一个典型的基于Actor模型的应用会有一个监督者监督工人的运行。Erlang也内置了用于连接和监督的函数，让我们一起来了解一下。</p>
<h4 id="普通actor相互连接"><a class="header-anchor" href="#普通actor相互连接">¶</a>普通Actor相互连接</h4>
<p>虽然一般我们需要一个监督者监督工人有没有正确运行，但工人间也是可以相互连接的。这时任意一个工人崩溃都会导致其连接的所有工人一起崩溃。在下图中，虚线代表连接在一起的Erlang协程。</p>
<img src="/blog/2018/08/08/线程与协程-并发的魔法/erlanglinkedprocess.png">
<p>在下图中，P9崩溃导致它连接的所有工人都崩溃。</p>
<img src="/blog/2018/08/08/线程与协程-并发的魔法/erlanglinkedcrash.png">
<p>这意味着当我们创建一个协程组（如上图P1，P3，P10，P9，P4构成一个协程组）时，我们期望的是这些协程要么一起做对一件事，要么什么都不做。当因为一个错误导致任何一个协程出错时，其他协程会接收到出错的协程发送的错误信号，然后整个协程组都会被终止。下面用一个例子来说明协程间是怎样相互连接的。</p>
<pre><code>-module(linktest).
-export([linkfun/0]).

linkfun() -&gt;
    receive
        {From, {N, D}} -&gt;
        From ! N/D,
        linkfun();
        {_,{Pid}} -&gt;
        link(Pid),
        linkfun()
    end.
</code></pre>
<p>现在我们创建两个linkfun/0的协程，然后连接它们，最后故意让其中一个退出（通过除以0的方式）。</p>
<blockquote>
<p>1&gt; c(linktest).<br>
{ok,linktest}<br>
2&gt; Pid1 = spawn(linktest,linkfun,[]).<br>
&lt;0.67.0&gt;<br>
3&gt; Pid2 = spawn(linktest,linkfun,[]).<br>
&lt;0.69.0&gt;<br>
4&gt; Pid1 ! {self(), {Pid2}}. %连接两个协程<br>
{&lt;0.60.0&gt;,{&lt;0.69.0&gt;}}<br>
5&gt; Pid1 ! {self(), {2,0}}. %故意引发一个除以0的错误</p>
<p>=ERROR REPORT==== 15-Aug-2018::01:57:07 ===<br>
Error in process &lt;0.67.0&gt; with exit value:<br>
{badarith,[{linktest,linkfun,0,[{file,“linktest.erl”},{line,7}]}]}<br>
6&gt; erlang:process_info(Pid1). %使用erlang:process_info/1函数查看Pid1对应的协程状态<br>
undefined %undefined说明Pid1已经退出被回收了<br>
7&gt; erlang:process_info(Pid2). %查看Pid2对应的协程状态<br>
undefined %也是undefined，说明Pid1退出时连接的Pid2也退出了</p>
</blockquote>
<p>协程在发生错误的时候能自动退出防止更大的错误发生固然是好事。但是我们也希望系统有自我恢复的能力：可能某个协程出错只是因为网络暂时不通，当网络恢复时这个协程组应当可以恢复运作。为了做到这点，我们需要一些特殊的Actor：监视着或者监督者。</p>
<h4 id="普通actor监视其他actor"><a class="header-anchor" href="#普通actor监视其他actor">¶</a>普通Actor监视其他Actor</h4>
<p>使用monitor函数代替link函数可以创建一个单向连接，这时被监视的协程崩溃时监视者会收到一条崩溃消息，里面会记录被监视的协程出错的原因。监视者只有在处理完毕崩溃信息时才会崩溃。我们来创建两个协程测试一下。</p>
<pre><code>-module(monitortest).
-export([monitorfun/0]).

monitorfun(Pid) -&gt;
    Ref = monitor(process, Pid), %Ref是Erlang用来唯一引用一个协程的标识，因为Erlang可以直接搭建分布式系统，在不同的运行时上Pid可能会重复，但是Ref不会重复
    receive
        {'DOWN', Ref, process, Pid, Why} -&gt; %匹配崩溃消息
            io:format(&quot;~p died with: ~p, ~n&quot;, [Pid, Why]) %然后打印它
    end.
</code></pre>
<p>协程的崩溃消息是一个以’DOWN’开始的元组，模式匹配可以精确地匹配元组中的字符串和原子来确定收到的信息是否是需要的信息。而在模式匹配中填入一个已经存在的变量（这里是Ref）则表示需要保证收到的Ref和已经存在的Ref一致才能接收这条消息。剩余的Pid和Why则创建了两个变量表示崩溃协程的Pid和崩溃原因。</p>
<p>我们在控制台中测试一下这个函数。为了方便，我们用匿名函数直接在控制台中创建新的协程（Erlang中函数是一等公民，匿名函数可以在任何能传递变量的地方出现，甚至可以把一个匿名函数赋给变量）。</p>
<blockquote>
<p>1&gt; F = fun() -&gt;<br>
1&gt;     receive {X,Y} -&gt;<br>
1&gt;         X/Y<br>
1&gt;     end %receive的end<br>
1&gt;     end. %匿名函数的end<br>
#Fun&lt;erl_eval.20.99386804&gt;<br>
2&gt; c(monitortest).<br>
{ok,monitortest}<br>
3&gt; Pid = spawn(F) %匿名函数没有模块名，可以直接spawn<br>
&lt;0.63.0&gt;<br>
4&gt; MPid = spawn(monitortest, monitorfun, [Pid]). %将匿名函数的Pid传给monitor协程<br>
&lt;0.65.0&gt;<br>
5&gt; Pid ! {5,0}. %故意引发除以零错误<br>
&lt;0.63.0&gt; died with: {badarith,[{erlang,’/’,[5,0],[]}]}, {5,0} %monitor打印出了错误信息<br>
%省略控制台自动生成的错误信息<br>
6&gt; erlang:process_info(Pid).<br>
undefined %Pid对应的协程已经崩溃<br>
7&gt; erlang:process_info(MPid).<br>
undefined %监视协程在处理完被监视协程的错误后自己也会崩溃</p>
</blockquote>
<p>通过使用monitor函数，我们有了让一个Actor在其他Actor崩溃时处理最后的崩溃信息的能力。监视者可以在接收到崩溃信息后做任何需要的时，比如记录日志，重启崩溃的协程或者忽略错误直接退出。</p>
<h4 id="监督者监督其他actor"><a class="header-anchor" href="#监督者监督其他actor">¶</a>监督者监督其他Actor</h4>
<p>另一个有用的技术是将一个普通的Erlang协程转变为系统协程，也就是Actor模型中的监督者机制。系统协程可以捕获到和它相连的协程的错误信息，并且停止错误信息的传播。</p>
<pre><code>-module(systemprocesstest).
-export([systemprocfun/0]).

systemprocfun() -&gt;
    process_flag(trap_exit, true), %通过设置trap_exit为true获得捕获错误的能力
    receive 
        {'EXIT', Pid, Reason} -&gt; %匹配退出消息
            io:format(&quot;~p died with: ~p, ~n&quot;, [Pid, Reason]), %然后打印它
            systemprocfun(); %系统协程不会退出，因此可以继续执行
        {link, Pid} -&gt; %通过消息连接其他协程
            link(Pid),
            systemprocfun()
        end.
</code></pre>
<p>我们依旧使用上次创建的匿名函数测试一下</p>
<blockquote>
<p>%匿名函数省略<br>
1&gt; c(systemproctest).<br>
{ok,systemproctest}<br>
2&gt; SPid = spawn(systemproctest, systemprocfun, []).<br>
&lt;0.72.0&gt;<br>
3&gt; Pid1 = spawn(F).<br>
&lt;0.74.0&gt;<br>
4&gt; Pid2 = spawn(F).<br>
&lt;0.79.0&gt;<br>
5&gt; SPid ! {link, Pid1}.<br>
{link,&lt;0.74.0&gt;}<br>
6&gt; SPid ! {link, Pid2}.<br>
{link,&lt;0.79.0&gt;}<br>
7&gt; Pid1 ! {5,0}.<br>
&lt;0.74.0&gt; died with: {badarith,[{erlang,’/’,[5,0],[]}]}, %系统协程SPid打印出了Pid1崩溃原因<br>
{5,0}<br>
%省略控制台自动生成的错误信息<br>
8&gt; erlang:process_info(Pid1).<br>
undefined %Pid1已经崩溃<br>
9&gt; erlang:process_info(Pid2).<br>
[{current_function,{prim_eval,‘receive’,2}},…] %因为SPid阻断了退出信息，Pid2正常运行<br>
10&gt; erlang:process_info(SPid).<br>
[{current_function,{systemproctest,systemprocfun,0}},…] %Spid也正常运行</p>
</blockquote>
<p>我们看到，比起基于生成器的协程，Actor模型更佳简单易懂，而且由于Actor模型提供的协程开销很小，运行时可以创建数万个甚至数十万个协程。因此我们也不需要使用try…catch的结构做防御性编程（即预判可能的错误然后编写代码防止错误发生导致崩溃），而是使用补救性编程（在协程崩溃后让其他协程处理崩溃信息并重启协程）。如果对Erlang有兴趣想要了解更多Erlang和OTP的知识，推荐阅读Erlang程序设计（第2版）（Joe Armstrong著 人民邮电出版社出版）和Erlang/OTP并发编程实战（Martin Logan , Eric Merritt , Richard Carlsson著 人民邮电出版社出版）。</p>
<p>下面我们来看最后一种常见的并发模型————CSP模型。</p>
<h3 id="基于csp模型的协程-以golang为例"><a class="header-anchor" href="#基于csp模型的协程-以golang为例">¶</a>基于CSP模型的协程（以Golang为例）</h3>
<h4 id="csp模型和golang简介"><a class="header-anchor" href="#csp模型和golang简介">¶</a>CSP模型和Golang简介</h4>
<p><em>本节所有代码基于go1.10.3测试，由于Golang的版本迭代较快，以下代码可能会在更新或更旧的版本上编译或运行时有错误</em></p>
<p>和Actor模型一样，CSP模型也不是什么新产物。它的全称是Communicating sequential processes 通信顺序进程，于1978年被Tony Hoare提出。最近CSP重新兴起是因为谷歌在2009年发布了Golang。Golang借鉴了CSP模型的一些想法并加以改进，虽然并没有完全实现CSP模型的一些特性，Golang对协程和并发的支持也是极为优秀的。在Golang中，协程被称作goroutine（参照coroutine）。它和Erlang一样实现了对称协程，所有的代码都运行在goroutine上，使用一个协程调度器调度。与Actor模型类似，goroutine有自己的私有内存空间，运行时互不干扰。但不同之处在于Actor模型中每个Actor有一个自己的信箱，Actor间可以直接把消息传递到对方的信箱中，而CSP模型则是使用一个channel（信道）连接两个协程，channel不关心它的两端是什么协程在存取数据。channel和goroutine都可以很方便地在Golang中调用。下面我们就来看一看Golang是如何优雅地处理并发的。</p>
<h4 id="两个简单的协程"><a class="header-anchor" href="#两个简单的协程">¶</a>两个简单的协程</h4>
<p>和C一样，Golang也是编译语言，因此我们不能在控制台测试。首先创建一个.go文件，然后尝试创建两个协程</p>
<pre><code>package main //只有在main包里的Golang函数才能直接执行

import &quot;fmt&quot; //这是Go标准库，用来格式化信息。这里我们用它来打印信息

func main() { //和C一样，Golang从main函数开始执行，注意在Golang里开始的大括号不能转行
	fmt.Println(&quot;main function start&quot;) //Golang的语句不用分号分隔
	ch := make(chan string, 2) //Golang是强类型语言，因此一般来说一个channel只能传递一种类型，这里channel传递的是string类型数据，2表示这个channel有一个能存放两个值的缓冲区
    go testfunc(&quot;1&quot;, ch) //go关键字表示后面的函数会在一个新的goroutine中运行
    go testfunc(&quot;2&quot;, ch) 
    fmt.Println(&lt;-ch) //&lt;-操作符用来操作channel，放在channel右边表示存入，左边表示取出。channel是一个FIFO，因此最先存放进去的值会被最先取出
    fmt.Println(&lt;-ch) //&lt;-一次只会取一个值，所以需要取两次
    fmt.Println(&quot;program exit&quot;)
}

func testfunc(id string, ch chan string) { //Golang的类型声明放在变量名后
    fmt.Println(&quot;Goroutine&quot;+id+&quot; started&quot;)
    ch &lt;- (&quot;Message from Goroutine&quot; + id)
    fmt.Println(&quot;Goroutine&quot; + id + &quot; exit&quot;)
}
</code></pre>
<p>下面我们来编译运行一下</p>
<blockquote>
<p>$go build test.go //这里写你的文件名<br>
$./test<br>
main function start<br>
Goroutine2 started<br>
Goroutine2 exit<br>
Message from Goroutine2<br>
Goroutine1 started<br>
Goroutine1 exit<br>
Message from Goroutine1<br>
program exit</p>
</blockquote>
<p>多运行几次可能结果和上面不同，这是因为Golang运行时会自动安排goroutine运行时间。Golang的make函数用来创建任何数据结构并返回一个指针。如果channel没有指定大小，那么channel的大小默认为1。如果channel满了，ch&lt;-会阻塞直到channel有空位为止。如果channel里没有东西，&lt;-ch会阻塞直到channel里有数据为止。Golang的并发就是这么简单：使用go关键字让一个函数变成一个goroutine，然后用channel同步取值。</p>
<h4 id="一个更复杂的例子？"><a class="header-anchor" href="#一个更复杂的例子？">¶</a>一个更复杂的例子？</h4>
<p>Golang的协程大部分时候都可以像上文那样简单使用，而里面的细节则十分复杂。而另一方面，CSP模型没有规定该怎样处理错误（的确有很多这样的论文，但各自的实现都不相同）。而Golang的错误处理仅仅是返回一个error值，这也是这个语言被很多人批评的地方。因此这篇文章就不再进一步讨论。另外，CSP本身也是一个数学定义的语言，因此有兴趣的可以了解更多关于它的信息。如果想要真正使用Golang的标准库编写程序，这已经超出了这篇文章讨论的范围（而且这篇文章已经很长了），可以阅读Go语言实战（Brian Ketelsen Erik St. Martin William Kenned著 人民邮电出版社出版）和Go语言圣经（中文版 <a href="http://golang-china.github.io/gopl-zh/" target="_blank" rel="noopener">http://golang-china.github.io/gopl-zh/</a> 英文原版 <a href="http://gopl.io/" target="_blank" rel="noopener">http://gopl.io/</a> ）</p>
<p>那么，这篇文章到此就告一段落了，希望大家能帮助我指出我的错误，谢谢。</p>

        </div>
      </div>
    </div>
  </div>
</article>



    <!-- Footer -->
<footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <p class="copyright text-muted">
          Theme By <a target="_blank" href="https://github.com/levblanc">Levblanc.</a>
          Inspired By <a target="_blank" href="https://github.com/klugjo/hexo-theme-clean-blog">Clean Blog.</a>
        <p class="copyright text-muted">
          Powered By <a target="_blank" href="https://hexo.io/">Hexo.</a>
        </p>
      </div>
    </div>
  </div>
</footer>


    <!-- After Footer Scripts -->
<script src="/blog/js/highlight.pack.js"></script>
<script>
  document.addEventListener("DOMContentLoaded", function(event) {
    var codeBlocks = Array.prototype.slice.call(document.getElementsByTagName('pre'))
    codeBlocks.forEach(function(block, index) {
      hljs.highlightBlock(block);
    });
  });
</script>

  </body>
</html>

